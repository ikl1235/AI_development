{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow_sigmoid_basic NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /~/deep_learning_zeroToAll/train-images-idx3-ubyte.gz\n",
      "Extracting /~/deep_learning_zeroToAll/train-labels-idx1-ubyte.gz\n",
      "Extracting /~/deep_learning_zeroToAll/t10k-images-idx3-ubyte.gz\n",
      "Extracting /~/deep_learning_zeroToAll/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 cost =  2.996679431\n",
      "Epoch: 0002 cost =  1.148799383\n",
      "Epoch: 0003 cost =  0.908504287\n",
      "Epoch: 0004 cost =  0.791161368\n",
      "Epoch: 0005 cost =  0.716022960\n",
      "Epoch: 0006 cost =  0.663118176\n",
      "Epoch: 0007 cost =  0.622578404\n",
      "Epoch: 0008 cost =  0.590757774\n",
      "Epoch: 0009 cost =  0.564415528\n",
      "Epoch: 0010 cost =  0.542386433\n",
      "Epoch: 0011 cost =  0.523108893\n",
      "Epoch: 0012 cost =  0.507294027\n",
      "Epoch: 0013 cost =  0.493484892\n",
      "Epoch: 0014 cost =  0.481025273\n",
      "Epoch: 0015 cost =  0.469802035\n",
      "Learning finished\n",
      "Accuracy:  0.8934\n",
      "Label:  [2]\n",
      "Prediction:  [8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    " \n",
    "# read data\n",
    "mnist = input_data.read_data_sets(\"/~/deep_learning_zeroToAll/\", one_hot=True)\n",
    " \n",
    "nb_classes = 10\n",
    " \n",
    "X = tf.placeholder(tf.float32,[None,784])\n",
    "Y = tf.placeholder(tf.float32,[None,nb_classes])\n",
    " \n",
    "W = tf.Variable(tf.random_normal([784,nb_classes]))\n",
    "b = tf.Variable(tf.random_normal([nb_classes]))\n",
    " \n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    " \n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis = 1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
    " \n",
    "is_correct = tf.equal(tf.arg_max(hypothesis,1), tf.arg_max(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
    " \n",
    "training_epochs = 30\n",
    "batch_size = 100\n",
    " \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    " \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _= sess.run([cost,optimizer], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    " \n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\n",
    "    print(\"Learning finished\")\n",
    "    print(\"Accuracy: \", accuracy.eval(session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
    " \n",
    "    # Get one and predict using matplotlib\n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "    print(\"Prediction: \", sess.run(tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    " \n",
    "    plt.imshow(mnist.test.images[r:r + 1].reshape(28, 28),cmap='Greys',interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow_Relu_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /~/deep_learning_zeroToAll/train-images-idx3-ubyte.gz\n",
      "Extracting /~/deep_learning_zeroToAll/train-labels-idx1-ubyte.gz\n",
      "Extracting /~/deep_learning_zeroToAll/t10k-images-idx3-ubyte.gz\n",
      "Extracting /~/deep_learning_zeroToAll/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-5-410274e0c5a5>:30: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch: 0001 cost =  164.621222184\n",
      "Epoch: 0002 cost =  40.283556506\n",
      "Epoch: 0003 cost =  25.503178148\n",
      "Epoch: 0004 cost =  17.973545398\n",
      "Epoch: 0005 cost =  13.187028469\n",
      "Epoch: 0006 cost =  9.863583258\n",
      "Epoch: 0007 cost =  7.470922764\n",
      "Epoch: 0008 cost =  5.696179271\n",
      "Epoch: 0009 cost =  4.201767175\n",
      "Epoch: 0010 cost =  3.266437993\n",
      "Epoch: 0011 cost =  2.511214670\n",
      "Epoch: 0012 cost =  1.936398911\n",
      "Epoch: 0013 cost =  1.485138132\n",
      "Epoch: 0014 cost =  1.241559559\n",
      "Epoch: 0015 cost =  0.915303291\n",
      "Learning finished\n",
      "Accuracy:  0.9453\n",
      "Label:  [9]\n",
      "Prediction:  [8]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAANJ0lEQVR4nO3df6xU9ZnH8c8HLSYKEliuLlqysMSElSZLmwloXItrs42/Ijaxm6JpaEKW/qFJG/vHKptY/9RVSxqywdAVC5uuDQkQiJJuDdaYxtg4KiguWS8aLBTkXtSkNjF2wWf/uIfNFe+cucyZmTPc5/1KJjNznjn3PDnwmTNzvjPzdUQIwNQ3re4GAPQHYQeSIOxAEoQdSIKwA0lc2M+NzZ07NxYsWNDPTQKpHD58WCdPnvREtUpht32TpJ9KukDSv0fEw2WPX7BggZrNZpVNAijRaDRa1jp+GW/7Akn/JulmSVdLWmX76k7/HoDeqvKefZmkQxHxbkT8WdIvJa3sTlsAuq1K2K+UdGTc/aPFss+xvdZ203ZzdHS0wuYAVFEl7BOdBPjCZ28jYlNENCKiMTQ0VGFzAKqoEvajkuaPu/9lSceqtQOgV6qE/RVJV9leaHu6pO9I2t2dtgB0W8dDbxFxyva9kv5LY0NvmyPira51BqCrKo2zR8QeSXu61AuAHuLjskAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRRaRZX9EdElNabzWbL2rJly0rXvf3220vr27ZtK61fdNFFpXUMjkpht31Y0seSTks6FRGNbjQFoPu6cWT/+4g42YW/A6CHeM8OJFE17CHp17Zftb12ogfYXmu7abs5OjpacXMAOlU17NdFxNck3SzpHttfP/sBEbEpIhoR0RgaGqq4OQCdqhT2iDhWXI9I2imp/NQvgNp0HHbbl9ieeea2pG9KOtCtxgB0V5Wz8ZdL2mn7zN/5z4j4VVe6wuecOHGitH7NNde0rE2bVv58/swzz5TWX3755dL6ihUrSusYHB2HPSLelfS3XewFQA8x9AYkQdiBJAg7kARhB5Ig7EASfMX1PPDss892vO5LL71UWt+/f39p/dprr+142xgsHNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2QfAp59+Wlp/8MEHS+sLFy5sWVuyZEnpusuXLy+tY+rgyA4kQdiBJAg7kARhB5Ig7EAShB1IgrADSTDOPgD27dtXWn///fdL60888UTL2owZMzrqCVMPR3YgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIJx9ing2LFjdbeA80DbI7vtzbZHbB8Yt2yO7edsDxfXs3vbJoCqJvMy/ueSbjpr2f2S9kbEVZL2FvcBDLC2YY+IFyV9eNbilZK2FLe3SLqjy30B6LJOT9BdHhHHJam4vqzVA22vtd203RwdHe1wcwCq6vnZ+IjYFBGNiGgMDQ31enMAWug07Cdsz5Ok4nqkey0B6IVOw75b0uri9mpJu7rTDoBeaTvObvtpSTdImmv7qKQfS3pY0jbbayT9XtK3e9nkVLd48eLS+pw5c0rru3a1fq594IEHStedPn16aR1TR9uwR8SqFqVvdLkXAD3Ex2WBJAg7kARhB5Ig7EAShB1Igq+4DoBZs2aV1lesWFFa37lzZ8vakSNHStddtGhRab1Or7/+emn9scceK61v3LixZe3SSy/tqKfzGUd2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfbzwNatW0vrM2fObFnbsGFD6brr168vrdsurVfxwQcflNbvvvvu0vrp06dL6xdffPE59zSVcWQHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQYZz8PXHhh5/9M7cbZly9fXlpftarVjwtPzvDwcMvarbfeWrruO++8U1p/7733SutV9ttUxJEdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgIPI80G68+Pnnn29Zu/HGG0vXXb16dWn9qaeeKq2388ILL7Sstfs++iOPPFJav+KKKzppKa22R3bbm22P2D4wbtlDtv9ge19xuaW3bQKoajIv438u6aYJlq+PiKXFZU932wLQbW3DHhEvSvqwD70A6KEqJ+jutf1G8TJ/dqsH2V5ru2m7OTo6WmFzAKroNOwbJS2StFTScUmPt3pgRGyKiEZENIaGhjrcHICqOgp7RJyIiNMR8Zmkn0la1t22AHRbR2G3PW/c3W9JOtDqsQAGQ9txdttPS7pB0lzbRyX9WNINtpdKCkmHJX2/hz2mN21a+XPy9ddf37L26KOPlq77+OMt34FJkvbv319aP3nyZGm9zLp160rr9913X2m93X7B57UNe0RM9OsFT/agFwA9xFMjkARhB5Ig7EAShB1IgrADSfAV1ymgbAiq3fBVu/onn3xSWl+2rPzzVIcOHWpZa/cz1gytdRd7E0iCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJwdpSKitH7q1KnSetm0zLfddltHPaEzHNmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2VFqZGSktP7222+X1tt9Xx79w5EdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnB2l9uzZU3cL6JK2R3bb823/xvZB22/Z/kGxfI7t52wPF9eze98ugE5N5mX8KUk/ioi/kXSNpHtsXy3pfkl7I+IqSXuL+wAGVNuwR8TxiHituP2xpIOSrpS0UtKW4mFbJN3RqyYBVHdOJ+hsL5D0VUm/k3R5RByXxp4QJF3WYp21tpu2m6Ojo9W6BdCxSYfd9gxJ2yX9MCL+ONn1ImJTRDQiojE0NNRJjwC6YFJht/0ljQX9FxGxo1h8wva8oj5PUvnXowDUqu3Qm21LelLSwYj4ybjSbkmrJT1cXO/qSYeo1fDwcKX177zzzi51gqomM85+naTvSnrT9r5i2TqNhXyb7TWSfi/p271pEUA3tA17RPxWkluUv9HddgD0Ch+XBZIg7EAShB1IgrADSRB2IAm+4opSs2bNqrT+jh07WtbWrFlT6W/j3HBkB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkHBF921ij0Yhms9m37aG6dj8ltnjx4tL6kiVLWtba/Uz1jBkzSuv4okajoWazOeG3VDmyA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASfJ8dpdrN4rNhw4bS+vbt21vWPvroo9J1GWfvLo7sQBKEHUiCsANJEHYgCcIOJEHYgSQIO5DEZOZnny9pq6S/lPSZpE0R8VPbD0n6J0lnvvC8LiLKv6CMKeeuu+6qVEf/TOZDNack/SgiXrM9U9Krtp8rausj4rHetQegWyYzP/txSceL2x/bPijpyl43BqC7zuk9u+0Fkr4q6XfFonttv2F7s+3ZLdZZa7tpu9nuJ44A9M6kw257hqTtkn4YEX+UtFHSIklLNXbkf3yi9SJiU0Q0IqLR7nPWAHpnUmG3/SWNBf0XEbFDkiLiREScjojPJP1M0rLetQmgqrZht21JT0o6GBE/Gbd83riHfUvSge63B6BbJnM2/jpJ35X0pu19xbJ1klbZXiopJB2W9P2edAigKyZzNv63kib6HWrG1IHzCJ+gA5Ig7EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJOGI6N/G7FFJ741bNFfSyb41cG4GtbdB7Uuit051s7e/iogJf/+tr2H/wsbtZkQ0amugxKD2Nqh9SfTWqX71xst4IAnCDiRRd9g31bz9MoPa26D2JdFbp/rSW63v2QH0T91HdgB9QtiBJGoJu+2bbP+P7UO276+jh1ZsH7b9pu19tps197LZ9ojtA+OWzbH9nO3h4nrCOfZq6u0h238o9t0+27fU1Nt827+xfdD2W7Z/UCyvdd+V9NWX/db39+y2L5D0tqR/kHRU0iuSVkXEf/e1kRZsH5bUiIjaP4Bh++uS/iRpa0R8pVj2r5I+jIiHiyfK2RHxzwPS20OS/lT3NN7FbEXzxk8zLukOSd9TjfuupK9/VB/2Wx1H9mWSDkXEuxHxZ0m/lLSyhj4GXkS8KOnDsxavlLSluL1FY/9Z+q5FbwMhIo5HxGvF7Y8lnZlmvNZ9V9JXX9QR9islHRl3/6gGa773kPRr26/aXlt3MxO4PCKOS2P/eSRdVnM/Z2s7jXc/nTXN+MDsu06mP6+qjrBPNJXUII3/XRcRX5N0s6R7ipermJxJTePdLxNMMz4QOp3+vKo6wn5U0vxx978s6VgNfUwoIo4V1yOSdmrwpqI+cWYG3eJ6pOZ+/t8gTeM90TTjGoB9V+f053WE/RVJV9leaHu6pO9I2l1DH19g+5LixIlsXyLpmxq8qah3S1pd3F4taVeNvXzOoEzj3WqacdW872qf/jwi+n6RdIvGzsi/I+lf6uihRV9/LWl/cXmr7t4kPa2xl3X/q7FXRGsk/YWkvZKGi+s5A9Tbf0h6U9IbGgvWvJp6+zuNvTV8Q9K+4nJL3fuupK++7Dc+LgskwSfogCQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJ/wPIp+4b1e9RVwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    " \n",
    "tf.set_random_seed(777)\n",
    "# read data\n",
    "mnist = input_data.read_data_sets(\"/~/deep_learning_zeroToAll/\", one_hot=True)\n",
    " \n",
    "nb_classes = 10\n",
    " \n",
    "X = tf.placeholder(tf.float32,[None,784])\n",
    "Y = tf.placeholder(tf.float32,[None,nb_classes])\n",
    " \n",
    "# W = tf.Variable(tf.random_normal([784,nb_classes]))\n",
    "# b = tf.Variable(tf.random_normal([nb_classes]))\n",
    " \n",
    "W1 = tf.Variable(tf.random_normal([784,256]))\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    " \n",
    "W2 = tf.Variable(tf.random_normal([256,256]))\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    " \n",
    "W3 = tf.Variable(tf.random_normal([256,10]))\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2, W3) + b3\n",
    " \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(cost)\n",
    " \n",
    "is_correct = tf.equal(tf.arg_max(hypothesis,1), tf.arg_max(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
    " \n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    " \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    " \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _= sess.run([cost,optimizer], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    " \n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\n",
    "    print(\"Learning finished\")\n",
    "    print(\"Accuracy: \", accuracy.eval(session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
    " \n",
    "    # Get one and predict using matplotlib\n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "    print(\"Prediction: \", sess.run(\n",
    "        tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    " \n",
    "    plt.imshow(\n",
    "        mnist.test.images[r:r + 1].reshape(28, 28),\n",
    "        cmap='Greys',\n",
    "        interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow_Relu_Xaviar_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-5136141bcd40>:9: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /~/deep_learning_zeroToAll/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /~/deep_learning_zeroToAll/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting /~/deep_learning_zeroToAll/t10k-images-idx3-ubyte.gz\n",
      "Extracting /~/deep_learning_zeroToAll/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From <ipython-input-1-5136141bcd40>:31: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-1-5136141bcd40>:34: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.math.argmax` instead\n",
      "Epoch: 0001 cost =  0.300870271\n",
      "Epoch: 0002 cost =  0.113753656\n",
      "Epoch: 0003 cost =  0.073694513\n",
      "Epoch: 0004 cost =  0.052128501\n",
      "Epoch: 0005 cost =  0.039068607\n",
      "Epoch: 0006 cost =  0.029106237\n",
      "Epoch: 0007 cost =  0.024946751\n",
      "Epoch: 0008 cost =  0.020587393\n",
      "Epoch: 0009 cost =  0.014509290\n",
      "Epoch: 0010 cost =  0.015282019\n",
      "Epoch: 0011 cost =  0.010616271\n",
      "Epoch: 0012 cost =  0.011566402\n",
      "Epoch: 0013 cost =  0.010238586\n",
      "Epoch: 0014 cost =  0.009036507\n",
      "Epoch: 0015 cost =  0.009406061\n",
      "Learning finished\n",
      "Accuracy:  0.9799\n",
      "Label:  [8]\n",
      "Prediction:  [8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    " \n",
    "tf.reset_default_graph()\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "# read data\n",
    "mnist = input_data.read_data_sets(\"/~/deep_learning_zeroToAll/\", one_hot=True)\n",
    " \n",
    "nb_classes = 10\n",
    " \n",
    "X = tf.placeholder(tf.float32,[None,784])\n",
    "Y = tf.placeholder(tf.float32,[None,nb_classes])\n",
    " \n",
    "# W = tf.Variable(tf.random_normal([784,nb_classes]))\n",
    "# b = tf.Variable(tf.random_normal([nb_classes]))\n",
    " \n",
    "W1 = tf.get_variable(\"W1\",shape=[784,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    " \n",
    "W2 = tf.get_variable(\"W2\",shape=[256,256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    " \n",
    "W3 = tf.get_variable(\"W3\",shape=[256,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2, W3) + b3\n",
    " \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(cost)\n",
    " \n",
    "is_correct = tf.equal(tf.arg_max(hypothesis,1), tf.arg_max(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
    " \n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    " \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    " \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _= sess.run([cost,optimizer], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    " \n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\n",
    "    print(\"Learning finished\")\n",
    "    print(\"Accuracy: \", accuracy.eval(session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
    " \n",
    "    # Get one and predict using matplotlib\n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "    print(\"Prediction: \", sess.run(\n",
    "        tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    " \n",
    "    plt.imshow(\n",
    "        mnist.test.images[r:r + 1].reshape(28, 28),\n",
    "        cmap='Greys',\n",
    "        interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "expand the number of layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /~/deep_learning_zeroToAll/train-images-idx3-ubyte.gz\n",
      "Extracting /~/deep_learning_zeroToAll/train-labels-idx1-ubyte.gz\n",
      "Extracting /~/deep_learning_zeroToAll/t10k-images-idx3-ubyte.gz\n",
      "Extracting /~/deep_learning_zeroToAll/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 cost =  0.296416299\n",
      "Epoch: 0002 cost =  0.105913901\n",
      "Epoch: 0003 cost =  0.072827831\n",
      "Epoch: 0004 cost =  0.053160011\n",
      "Epoch: 0005 cost =  0.039780915\n",
      "Epoch: 0006 cost =  0.036420490\n",
      "Epoch: 0007 cost =  0.030877478\n",
      "Epoch: 0008 cost =  0.026319738\n",
      "Epoch: 0009 cost =  0.023828820\n",
      "Epoch: 0010 cost =  0.018878703\n",
      "Epoch: 0011 cost =  0.019179811\n",
      "Epoch: 0012 cost =  0.018810492\n",
      "Epoch: 0013 cost =  0.014720884\n",
      "Epoch: 0014 cost =  0.014314971\n",
      "Epoch: 0015 cost =  0.015148447\n",
      "Learning finished\n",
      "Accuracy:  0.9811\n",
      "Label:  [1]\n",
      "Prediction:  [1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "# read data\n",
    "mnist = input_data.read_data_sets(\"/~/deep_learning_zeroToAll/\", one_hot=True)\n",
    " \n",
    "nb_classes = 10\n",
    " \n",
    "X = tf.placeholder(tf.float32,[None,784])\n",
    "Y = tf.placeholder(tf.float32,[None,nb_classes])\n",
    " \n",
    "# W = tf.Variable(tf.random_normal([784,nb_classes]))\n",
    "# b = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "W1 = tf.get_variable(\"W1\",shape=[784,512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([512]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    " \n",
    "W2 = tf.get_variable(\"W2\",shape=[512,512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    " \n",
    "W3 = tf.get_variable(\"W3\",shape=[512,512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([512]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    " \n",
    "W4 = tf.get_variable(\"W4\",shape=[512,512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([512]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    " \n",
    "W5 = tf.get_variable(\"W5\",shape=[512,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5\n",
    " \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(cost)\n",
    " \n",
    "is_correct = tf.equal(tf.arg_max(hypothesis,1), tf.arg_max(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
    " \n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    " \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    " \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _= sess.run([cost,optimizer], feed_dict={X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    " \n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\n",
    "    print(\"Learning finished\")\n",
    "    print(\"Accuracy: \", accuracy.eval(session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))\n",
    " \n",
    "    # Get one and predict using matplotlib\n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "    print(\"Prediction: \", sess.run(\n",
    "        tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    " \n",
    "    plt.imshow(\n",
    "        mnist.test.images[r:r + 1].reshape(28, 28),\n",
    "        cmap='Greys',\n",
    "        interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorflow_drop-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /~/deep_learning_zeroToAll/train-images-idx3-ubyte.gz\n",
      "Extracting /~/deep_learning_zeroToAll/train-labels-idx1-ubyte.gz\n",
      "Extracting /~/deep_learning_zeroToAll/t10k-images-idx3-ubyte.gz\n",
      "Extracting /~/deep_learning_zeroToAll/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From <ipython-input-7-9565c0c70aa1>:24: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Epoch: 0001 cost =  0.468856147\n",
      "Epoch: 0002 cost =  0.169603267\n",
      "Epoch: 0003 cost =  0.130259501\n",
      "Epoch: 0004 cost =  0.105948503\n",
      "Epoch: 0005 cost =  0.090093881\n",
      "Epoch: 0006 cost =  0.083276808\n",
      "Epoch: 0007 cost =  0.075004868\n",
      "Epoch: 0008 cost =  0.067194916\n",
      "Epoch: 0009 cost =  0.062012865\n",
      "Epoch: 0010 cost =  0.059268949\n",
      "Epoch: 0011 cost =  0.057426236\n",
      "Epoch: 0012 cost =  0.054701197\n",
      "Epoch: 0013 cost =  0.048475568\n",
      "Epoch: 0014 cost =  0.046776195\n",
      "Epoch: 0015 cost =  0.047594910\n",
      "Learning finished\n",
      "Accuracy:  0.9829\n",
      "Label:  [2]\n",
      "Prediction:  [2]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "# read data\n",
    "mnist = input_data.read_data_sets(\"/~/deep_learning_zeroToAll/\", one_hot=True)\n",
    " \n",
    "nb_classes = 10\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    " \n",
    "X = tf.placeholder(tf.float32,[None,784])\n",
    "Y = tf.placeholder(tf.float32,[None,nb_classes])\n",
    " \n",
    "# W = tf.Variable(tf.random_normal([784,nb_classes]))\n",
    "# b = tf.Variable(tf.random_normal([nb_classes]))\n",
    " \n",
    "W1 = tf.get_variable(\"W1\",shape=[784,512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([512]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    " \n",
    "W2 = tf.get_variable(\"W2\",shape=[512,512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    " \n",
    "W3 = tf.get_variable(\"W3\",shape=[512,512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([512]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    " \n",
    "W4 = tf.get_variable(\"W4\",shape=[512,512], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([512]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    " \n",
    "W5 = tf.get_variable(\"W5\",shape=[512,10], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5\n",
    " \n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(cost)\n",
    " \n",
    "is_correct = tf.equal(tf.arg_max(hypothesis,1), tf.arg_max(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct,tf.float32))\n",
    " \n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    " \n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    " \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _= sess.run([cost,optimizer], feed_dict={X: batch_xs, Y: batch_ys, keep_prob: 0.7})\n",
    "            avg_cost += c / total_batch\n",
    " \n",
    "        print('Epoch:', '%04d' % (epoch + 1), 'cost = ', '{:.9f}'.format(avg_cost))\n",
    "    print(\"Learning finished\")\n",
    "    print(\"Accuracy: \", accuracy.eval(session=sess, feed_dict={X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    " \n",
    "    # Get one and predict using matplotlib\n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "    print(\"Prediction: \", sess.run(\n",
    "        tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))\n",
    " \n",
    "    plt.imshow(\n",
    "        mnist.test.images[r:r + 1].reshape(28, 28),\n",
    "        cmap='Greys',\n",
    "        interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
